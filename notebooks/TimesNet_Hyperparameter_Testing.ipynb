{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8b3e2a9",
   "metadata": {},
   "source": [
    "# TimesNet Hyperparameter Testing Report\n",
    "\n",
    "## Implementation Reference\n",
    "This report is based on the **TSLib (Time-Series-Library)** implementation of TimesNet from:\n",
    "- GitHub: https://github.com/thuml/Time-Series-Library\n",
    "- Paper: TimesNet: Temporal 2D-Variation Modeling for General Time Series Analysis (ICLR 2023)\n",
    "\n",
    "## Model Overview\n",
    "TimesNet is a task-general foundation model for time series analysis that:\n",
    "1. Transforms 1D time series into 2D space based on multi-periodicity\n",
    "2. Captures intraperiod- and interperiod-variations using 2D inception blocks\n",
    "3. Uses FFT to discover dominant periods and adaptively aggregates representations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895d4b39",
   "metadata": {},
   "source": [
    "## 1. Hyperparameter Identification\n",
    "\n",
    "### 1.1 TimesNet-Specific Hyperparameters (from paper and implementation)\n",
    "\n",
    "| Hyperparameter | Description | Default | Range/Options |\n",
    "|----------------|-------------|---------|---------------|\n",
    "| `top_k` | Number of top frequencies to select from FFT | 5 | 1-10 |\n",
    "| `num_kernels` | Number of kernels in Inception block | 6 | 2-8 |\n",
    "| `d_model` | Model dimension (embedding dimension) | 16-512 | 8-512 |\n",
    "| `d_ff` | Feed-forward dimension | 32-2048 | 16-2048 |\n",
    "| `e_layers` | Number of encoder layers (TimesBlocks) | 2 | 1-4 |\n",
    "\n",
    "### 1.2 General Training Hyperparameters\n",
    "\n",
    "| Hyperparameter | Description | Default | Range/Options |\n",
    "|----------------|-------------|---------|---------------|\n",
    "| `seq_len` | Input sequence length | 96 | 24-512 |\n",
    "| `pred_len` | Prediction sequence length | 96 | 24-720 |\n",
    "| `label_len` | Start token length | 48 | 0-seq_len |\n",
    "| `batch_size` | Training batch size | 32 | 16-128 |\n",
    "| `learning_rate` | Optimizer learning rate | 0.0001 | 1e-5 to 1e-2 |\n",
    "| `dropout` | Dropout rate | 0.1 | 0.0-0.5 |\n",
    "| `embed` | Time features encoding | 'timeF' | ['timeF', 'fixed', 'learned'] |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06705eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.8.0+cu128\n",
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set working directory\n",
    "os.chdir('/home/ayush/Desktop/tslib')\n",
    "sys.path.insert(0, '/home/ayush/Desktop/tslib')\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76007f4",
   "metadata": {},
   "source": [
    "## 2. Download and Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bece1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download ETT dataset if not present\n",
    "import urllib.request\n",
    "import os\n",
    "\n",
    "dataset_dir = '/home/ayush/Desktop/tslib/dataset/ETT-small'\n",
    "os.makedirs(dataset_dir, exist_ok=True)\n",
    "\n",
    "# ETT dataset URLs (from the official repository)\n",
    "ett_files = {\n",
    "    'ETTh1.csv': 'https://raw.githubusercontent.com/zhouhaoyi/ETDataset/main/ETT-small/ETTh1.csv',\n",
    "    'ETTh2.csv': 'https://raw.githubusercontent.com/zhouhaoyi/ETDataset/main/ETT-small/ETTh2.csv',\n",
    "    'ETTm1.csv': 'https://raw.githubusercontent.com/zhouhaoyi/ETDataset/main/ETT-small/ETTm1.csv',\n",
    "    'ETTm2.csv': 'https://raw.githubusercontent.com/zhouhaoyi/ETDataset/main/ETT-small/ETTm2.csv'\n",
    "}\n",
    "\n",
    "for filename, url in ett_files.items():\n",
    "    filepath = os.path.join(dataset_dir, filename)\n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"Downloading {filename}...\")\n",
    "        try:\n",
    "            urllib.request.urlretrieve(url, filepath)\n",
    "            print(f\"Downloaded {filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading {filename}: {e}\")\n",
    "    else:\n",
    "        print(f\"{filename} already exists\")\n",
    "\n",
    "# Verify downloads\n",
    "print(\"\\nDataset directory contents:\")\n",
    "for f in os.listdir(dataset_dir):\n",
    "    print(f\"  {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0beaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and inspect the data\n",
    "df = pd.read_csv(os.path.join(dataset_dir, 'ETTh1.csv'))\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {list(df.columns)}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e407e0",
   "metadata": {},
   "source": [
    "## 3. Helper Functions for Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c174577b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import re\n",
    "import json\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "def run_timesnet_experiment(\n",
    "    # TimesNet-specific hyperparameters\n",
    "    top_k: int = 5,\n",
    "    num_kernels: int = 6,\n",
    "    d_model: int = 16,\n",
    "    d_ff: int = 32,\n",
    "    e_layers: int = 2,\n",
    "    # General hyperparameters\n",
    "    seq_len: int = 96,\n",
    "    pred_len: int = 96,\n",
    "    label_len: int = 48,\n",
    "    batch_size: int = 32,\n",
    "    learning_rate: float = 0.0001,\n",
    "    dropout: float = 0.1,\n",
    "    embed: str = 'timeF',\n",
    "    train_epochs: int = 10,\n",
    "    # Dataset config\n",
    "    data: str = 'ETTh1',\n",
    "    data_path: str = 'ETTh1.csv',\n",
    "    root_path: str = './dataset/ETT-small/',\n",
    "    features: str = 'M',\n",
    "    enc_in: int = 7,\n",
    "    # Run config\n",
    "    model_id: str = 'test',\n",
    "    patience: int = 3,\n",
    "    itr: int = 1\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Run a TimesNet experiment with specified hyperparameters.\n",
    "    Returns a dictionary with MSE, MAE, and other metrics.\n",
    "    \"\"\"\n",
    "    cmd = [\n",
    "        'python', '-u', 'run.py',\n",
    "        '--task_name', 'long_term_forecast',\n",
    "        '--is_training', '1',\n",
    "        '--root_path', root_path,\n",
    "        '--data_path', data_path,\n",
    "        '--model_id', model_id,\n",
    "        '--model', 'TimesNet',\n",
    "        '--data', data,\n",
    "        '--features', features,\n",
    "        '--seq_len', str(seq_len),\n",
    "        '--label_len', str(label_len),\n",
    "        '--pred_len', str(pred_len),\n",
    "        '--e_layers', str(e_layers),\n",
    "        '--d_layers', '1',\n",
    "        '--factor', '3',\n",
    "        '--enc_in', str(enc_in),\n",
    "        '--dec_in', str(enc_in),\n",
    "        '--c_out', str(enc_in),\n",
    "        '--d_model', str(d_model),\n",
    "        '--d_ff', str(d_ff),\n",
    "        '--top_k', str(top_k),\n",
    "        '--num_kernels', str(num_kernels),\n",
    "        '--dropout', str(dropout),\n",
    "        '--embed', embed,\n",
    "        '--batch_size', str(batch_size),\n",
    "        '--learning_rate', str(learning_rate),\n",
    "        '--train_epochs', str(train_epochs),\n",
    "        '--patience', str(patience),\n",
    "        '--itr', str(itr),\n",
    "        '--des', 'Exp'\n",
    "    ]\n",
    "    \n",
    "    print(f\"Running: {' '.join(cmd[:15])}...\")\n",
    "    \n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            cmd,\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            cwd='/home/ayush/Desktop/tslib',\n",
    "            timeout=3600  # 1 hour timeout\n",
    "        )\n",
    "        \n",
    "        output = result.stdout + result.stderr\n",
    "        \n",
    "        # Parse metrics from output\n",
    "        mse_match = re.search(r'mse[:\\s]+([0-9.]+)', output, re.IGNORECASE)\n",
    "        mae_match = re.search(r'mae[:\\s]+([0-9.]+)', output, re.IGNORECASE)\n",
    "        \n",
    "        metrics = {\n",
    "            'mse': float(mse_match.group(1)) if mse_match else None,\n",
    "            'mae': float(mae_match.group(1)) if mae_match else None,\n",
    "            'success': True if mse_match else False,\n",
    "            'output': output[-2000:] if len(output) > 2000 else output  # Last 2000 chars\n",
    "        }\n",
    "        \n",
    "        return metrics\n",
    "        \n",
    "    except subprocess.TimeoutExpired:\n",
    "        return {'mse': None, 'mae': None, 'success': False, 'output': 'Timeout'}\n",
    "    except Exception as e:\n",
    "        return {'mse': None, 'mae': None, 'success': False, 'output': str(e)}\n",
    "\n",
    "\n",
    "def format_results_table(results: List[Dict], param_name: str) -> pd.DataFrame:\n",
    "    \"\"\"Format results into a DataFrame for display.\"\"\"\n",
    "    df = pd.DataFrame(results)\n",
    "    df = df.sort_values(by='mse', ascending=True, na_position='last')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d88a33a",
   "metadata": {},
   "source": [
    "## 4. Base Model Configuration (Author's Recommended Settings)\n",
    "\n",
    "Based on the official scripts from TSLib for ETTh1 dataset:\n",
    "\n",
    "### Author's Base Configuration:\n",
    "```\n",
    "- seq_len: 96\n",
    "- pred_len: 96\n",
    "- e_layers: 2\n",
    "- d_model: 16\n",
    "- d_ff: 32\n",
    "- top_k: 5\n",
    "- num_kernels: 6 (default)\n",
    "- batch_size: 32\n",
    "- learning_rate: 0.0001\n",
    "- train_epochs: 10\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21881172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test base model configuration\n",
    "print(\"=\"*60)\n",
    "print(\"Testing Base Model Configuration (Author's Recommended)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "base_results = run_timesnet_experiment(\n",
    "    # TimesNet-specific (from paper/scripts)\n",
    "    top_k=5,\n",
    "    num_kernels=6,\n",
    "    d_model=16,\n",
    "    d_ff=32,\n",
    "    e_layers=2,\n",
    "    # General\n",
    "    seq_len=96,\n",
    "    pred_len=96,\n",
    "    label_len=48,\n",
    "    batch_size=32,\n",
    "    learning_rate=0.0001,\n",
    "    dropout=0.1,\n",
    "    embed='timeF',\n",
    "    train_epochs=10,\n",
    "    # Dataset\n",
    "    data='ETTh1',\n",
    "    data_path='ETTh1.csv',\n",
    "    model_id='ETTh1_base_96_96'\n",
    ")\n",
    "\n",
    "print(f\"\\nBase Model Results:\")\n",
    "print(f\"  MSE: {base_results.get('mse', 'N/A')}\")\n",
    "print(f\"  MAE: {base_results.get('mae', 'N/A')}\")\n",
    "print(f\"  Success: {base_results.get('success', False)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0eb023",
   "metadata": {},
   "source": [
    "## 5. Hyperparameter Testing\n",
    "\n",
    "We will test the following hyperparameters systematically:\n",
    "1. **top_k** - Number of top frequencies (core TimesNet parameter)\n",
    "2. **num_kernels** - Number of kernels in Inception block\n",
    "3. **d_model** - Model embedding dimension\n",
    "4. **d_ff** - Feed-forward dimension\n",
    "5. **e_layers** - Number of TimesBlock layers\n",
    "6. **learning_rate** - Optimizer learning rate\n",
    "7. **dropout** - Dropout rate\n",
    "8. **embed** - Time feature encoding method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b524dec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store all results\n",
    "all_results = {}\n",
    "\n",
    "# Base configuration (used as default for all tests)\n",
    "base_config = {\n",
    "    'top_k': 5,\n",
    "    'num_kernels': 6,\n",
    "    'd_model': 16,\n",
    "    'd_ff': 32,\n",
    "    'e_layers': 2,\n",
    "    'seq_len': 96,\n",
    "    'pred_len': 96,\n",
    "    'label_len': 48,\n",
    "    'batch_size': 32,\n",
    "    'learning_rate': 0.0001,\n",
    "    'dropout': 0.1,\n",
    "    'embed': 'timeF',\n",
    "    'train_epochs': 5,  # Reduced for faster testing\n",
    "    'data': 'ETTh1',\n",
    "    'data_path': 'ETTh1.csv'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c51886",
   "metadata": {},
   "source": [
    "### 5.1 Test top_k (Number of Top Frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f11b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"Testing top_k (Number of Top Frequencies)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "top_k_values = [1, 2, 3, 5, 7, 10]\n",
    "top_k_results = []\n",
    "\n",
    "for k in top_k_values:\n",
    "    print(f\"\\nTesting top_k = {k}\")\n",
    "    config = base_config.copy()\n",
    "    config['top_k'] = k\n",
    "    config['model_id'] = f'ETTh1_topk_{k}'\n",
    "    \n",
    "    result = run_timesnet_experiment(**config)\n",
    "    result['top_k'] = k\n",
    "    top_k_results.append(result)\n",
    "    \n",
    "    print(f\"  MSE: {result.get('mse', 'N/A')}, MAE: {result.get('mae', 'N/A')}\")\n",
    "\n",
    "all_results['top_k'] = top_k_results\n",
    "\n",
    "# Display results\n",
    "df_topk = pd.DataFrame(top_k_results)[['top_k', 'mse', 'mae', 'success']]\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"top_k Results Summary:\")\n",
    "display(df_topk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508ea30c",
   "metadata": {},
   "source": [
    "### 5.2 Test num_kernels (Number of Inception Kernels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897572e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"Testing num_kernels (Number of Inception Kernels)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "num_kernels_values = [2, 4, 6, 8]\n",
    "num_kernels_results = []\n",
    "\n",
    "for nk in num_kernels_values:\n",
    "    print(f\"\\nTesting num_kernels = {nk}\")\n",
    "    config = base_config.copy()\n",
    "    config['num_kernels'] = nk\n",
    "    config['model_id'] = f'ETTh1_numkernels_{nk}'\n",
    "    \n",
    "    result = run_timesnet_experiment(**config)\n",
    "    result['num_kernels'] = nk\n",
    "    num_kernels_results.append(result)\n",
    "    \n",
    "    print(f\"  MSE: {result.get('mse', 'N/A')}, MAE: {result.get('mae', 'N/A')}\")\n",
    "\n",
    "all_results['num_kernels'] = num_kernels_results\n",
    "\n",
    "# Display results\n",
    "df_nk = pd.DataFrame(num_kernels_results)[['num_kernels', 'mse', 'mae', 'success']]\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"num_kernels Results Summary:\")\n",
    "display(df_nk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27493f0a",
   "metadata": {},
   "source": [
    "### 5.3 Test d_model (Model Dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9c0a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"Testing d_model (Model Dimension)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "d_model_values = [8, 16, 32, 64, 128]\n",
    "d_model_results = []\n",
    "\n",
    "for dm in d_model_values:\n",
    "    print(f\"\\nTesting d_model = {dm}\")\n",
    "    config = base_config.copy()\n",
    "    config['d_model'] = dm\n",
    "    config['d_ff'] = dm * 2  # Keep d_ff proportional\n",
    "    config['model_id'] = f'ETTh1_dmodel_{dm}'\n",
    "    \n",
    "    result = run_timesnet_experiment(**config)\n",
    "    result['d_model'] = dm\n",
    "    d_model_results.append(result)\n",
    "    \n",
    "    print(f\"  MSE: {result.get('mse', 'N/A')}, MAE: {result.get('mae', 'N/A')}\")\n",
    "\n",
    "all_results['d_model'] = d_model_results\n",
    "\n",
    "# Display results\n",
    "df_dm = pd.DataFrame(d_model_results)[['d_model', 'mse', 'mae', 'success']]\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"d_model Results Summary:\")\n",
    "display(df_dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32abc4a3",
   "metadata": {},
   "source": [
    "### 5.4 Test e_layers (Number of TimesBlock Layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cc0694",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"Testing e_layers (Number of TimesBlock Layers)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "e_layers_values = [1, 2, 3, 4]\n",
    "e_layers_results = []\n",
    "\n",
    "for el in e_layers_values:\n",
    "    print(f\"\\nTesting e_layers = {el}\")\n",
    "    config = base_config.copy()\n",
    "    config['e_layers'] = el\n",
    "    config['model_id'] = f'ETTh1_elayers_{el}'\n",
    "    \n",
    "    result = run_timesnet_experiment(**config)\n",
    "    result['e_layers'] = el\n",
    "    e_layers_results.append(result)\n",
    "    \n",
    "    print(f\"  MSE: {result.get('mse', 'N/A')}, MAE: {result.get('mae', 'N/A')}\")\n",
    "\n",
    "all_results['e_layers'] = e_layers_results\n",
    "\n",
    "# Display results\n",
    "df_el = pd.DataFrame(e_layers_results)[['e_layers', 'mse', 'mae', 'success']]\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"e_layers Results Summary:\")\n",
    "display(df_el)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba9d664",
   "metadata": {},
   "source": [
    "### 5.5 Test learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5256d891",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"Testing learning_rate\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "lr_values = [0.00001, 0.00005, 0.0001, 0.0005, 0.001]\n",
    "lr_results = []\n",
    "\n",
    "for lr in lr_values:\n",
    "    print(f\"\\nTesting learning_rate = {lr}\")\n",
    "    config = base_config.copy()\n",
    "    config['learning_rate'] = lr\n",
    "    config['model_id'] = f'ETTh1_lr_{lr}'\n",
    "    \n",
    "    result = run_timesnet_experiment(**config)\n",
    "    result['learning_rate'] = lr\n",
    "    lr_results.append(result)\n",
    "    \n",
    "    print(f\"  MSE: {result.get('mse', 'N/A')}, MAE: {result.get('mae', 'N/A')}\")\n",
    "\n",
    "all_results['learning_rate'] = lr_results\n",
    "\n",
    "# Display results\n",
    "df_lr = pd.DataFrame(lr_results)[['learning_rate', 'mse', 'mae', 'success']]\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"learning_rate Results Summary:\")\n",
    "display(df_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffec736",
   "metadata": {},
   "source": [
    "### 5.6 Test dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd6ba78",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"Testing dropout\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "dropout_values = [0.0, 0.05, 0.1, 0.2, 0.3]\n",
    "dropout_results = []\n",
    "\n",
    "for do in dropout_values:\n",
    "    print(f\"\\nTesting dropout = {do}\")\n",
    "    config = base_config.copy()\n",
    "    config['dropout'] = do\n",
    "    config['model_id'] = f'ETTh1_dropout_{do}'\n",
    "    \n",
    "    result = run_timesnet_experiment(**config)\n",
    "    result['dropout'] = do\n",
    "    dropout_results.append(result)\n",
    "    \n",
    "    print(f\"  MSE: {result.get('mse', 'N/A')}, MAE: {result.get('mae', 'N/A')}\")\n",
    "\n",
    "all_results['dropout'] = dropout_results\n",
    "\n",
    "# Display results\n",
    "df_do = pd.DataFrame(dropout_results)[['dropout', 'mse', 'mae', 'success']]\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"dropout Results Summary:\")\n",
    "display(df_do)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a30a22",
   "metadata": {},
   "source": [
    "### 5.7 Test embed (Time Feature Encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9eace4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"Testing embed (Time Feature Encoding)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "embed_values = ['timeF', 'fixed', 'learned']\n",
    "embed_results = []\n",
    "\n",
    "for emb in embed_values:\n",
    "    print(f\"\\nTesting embed = {emb}\")\n",
    "    config = base_config.copy()\n",
    "    config['embed'] = emb\n",
    "    config['model_id'] = f'ETTh1_embed_{emb}'\n",
    "    \n",
    "    result = run_timesnet_experiment(**config)\n",
    "    result['embed'] = emb\n",
    "    embed_results.append(result)\n",
    "    \n",
    "    print(f\"  MSE: {result.get('mse', 'N/A')}, MAE: {result.get('mae', 'N/A')}\")\n",
    "\n",
    "all_results['embed'] = embed_results\n",
    "\n",
    "# Display results\n",
    "df_emb = pd.DataFrame(embed_results)[['embed', 'mse', 'mae', 'success']]\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"embed Results Summary:\")\n",
    "display(df_emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74094010",
   "metadata": {},
   "source": [
    "## 6. Metadata Feature Testing\n",
    "\n",
    "Test the effect of adding linear metadata features (-1 to 1 normalized):\n",
    "- Time of day\n",
    "- Day of the week\n",
    "- Day of the month\n",
    "- Month of the year\n",
    "- Season of the year\n",
    "- Holiday indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb61375f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset with metadata features\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "def add_metadata_features(df: pd.DataFrame, date_col: str = 'date') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Add linear metadata features normalized to [-1, 1] range.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df[date_col] = pd.to_datetime(df[date_col])\n",
    "    \n",
    "    # Time of day (0-23 hours -> -1 to 1)\n",
    "    df['hour_linear'] = (df[date_col].dt.hour / 11.5) - 1\n",
    "    \n",
    "    # Day of week (0-6 -> -1 to 1)\n",
    "    df['dayofweek_linear'] = (df[date_col].dt.dayofweek / 3) - 1\n",
    "    \n",
    "    # Day of month (1-31 -> -1 to 1)\n",
    "    df['dayofmonth_linear'] = ((df[date_col].dt.day - 1) / 15) - 1\n",
    "    \n",
    "    # Month of year (1-12 -> -1 to 1)\n",
    "    df['month_linear'] = ((df[date_col].dt.month - 1) / 5.5) - 1\n",
    "    \n",
    "    # Season (0-3 -> -1 to 1)\n",
    "    # Winter=0, Spring=1, Summer=2, Fall=3\n",
    "    df['season'] = (df[date_col].dt.month % 12 // 3)\n",
    "    df['season_linear'] = (df['season'] / 1.5) - 1\n",
    "    df = df.drop('season', axis=1)\n",
    "    \n",
    "    # Holiday indicator (simplified - weekends as holidays)\n",
    "    # 0 = weekday, 1 = weekend -> -1 to 1\n",
    "    df['holiday_linear'] = np.where(df[date_col].dt.dayofweek >= 5, 1, -1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Load and process data\n",
    "df_original = pd.read_csv('/home/ayush/Desktop/tslib/dataset/ETT-small/ETTh1.csv')\n",
    "df_with_meta = add_metadata_features(df_original, 'date')\n",
    "\n",
    "# Save modified dataset\n",
    "metadata_cols = ['hour_linear', 'dayofweek_linear', 'dayofmonth_linear', \n",
    "                 'month_linear', 'season_linear', 'holiday_linear']\n",
    "\n",
    "# Create dataset with metadata as additional input features\n",
    "df_with_meta.to_csv('/home/ayush/Desktop/tslib/dataset/ETT-small/ETTh1_with_metadata.csv', index=False)\n",
    "\n",
    "print(\"Metadata features added:\")\n",
    "print(df_with_meta[['date'] + metadata_cols].head(10))\n",
    "print(f\"\\nNew columns: {metadata_cols}\")\n",
    "print(f\"Dataset shape: {df_with_meta.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad8d0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"Testing Effect of Metadata Features\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Test without metadata (baseline)\n",
    "print(\"\\n1. Baseline (without metadata features):\")\n",
    "config_baseline = base_config.copy()\n",
    "config_baseline['model_id'] = 'ETTh1_no_metadata'\n",
    "config_baseline['enc_in'] = 7  # Original 7 features\n",
    "\n",
    "result_baseline = run_timesnet_experiment(**config_baseline)\n",
    "print(f\"  MSE: {result_baseline.get('mse', 'N/A')}, MAE: {result_baseline.get('mae', 'N/A')}\")\n",
    "\n",
    "# Test with metadata\n",
    "print(\"\\n2. With metadata features (6 additional features):\")\n",
    "config_metadata = base_config.copy()\n",
    "config_metadata['model_id'] = 'ETTh1_with_metadata'\n",
    "config_metadata['data_path'] = 'ETTh1_with_metadata.csv'\n",
    "config_metadata['enc_in'] = 13  # 7 original + 6 metadata\n",
    "config_metadata['data'] = 'custom'  # Use custom data loader\n",
    "\n",
    "result_metadata = run_timesnet_experiment(**config_metadata)\n",
    "print(f\"  MSE: {result_metadata.get('mse', 'N/A')}, MAE: {result_metadata.get('mae', 'N/A')}\")\n",
    "\n",
    "# Store results\n",
    "all_results['metadata'] = [\n",
    "    {'config': 'baseline', 'mse': result_baseline.get('mse'), 'mae': result_baseline.get('mae')},\n",
    "    {'config': 'with_metadata', 'mse': result_metadata.get('mse'), 'mae': result_metadata.get('mae')}\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"Metadata Feature Results:\")\n",
    "df_meta = pd.DataFrame(all_results['metadata'])\n",
    "display(df_meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b64e65a",
   "metadata": {},
   "source": [
    "## 7. Results Summary and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0d6aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization of all hyperparameter results\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "fig.suptitle('TimesNet Hyperparameter Testing Results (MSE)', fontsize=14)\n",
    "\n",
    "# Plot each hyperparameter's results\n",
    "param_plots = [\n",
    "    ('top_k', 'top_k'),\n",
    "    ('num_kernels', 'num_kernels'),\n",
    "    ('d_model', 'd_model'),\n",
    "    ('e_layers', 'e_layers'),\n",
    "    ('learning_rate', 'learning_rate'),\n",
    "    ('dropout', 'dropout'),\n",
    "    ('embed', 'embed'),\n",
    "    ('metadata', 'config')\n",
    "]\n",
    "\n",
    "for idx, (param_key, x_col) in enumerate(param_plots):\n",
    "    ax = axes[idx // 4, idx % 4]\n",
    "    \n",
    "    if param_key in all_results and all_results[param_key]:\n",
    "        df = pd.DataFrame(all_results[param_key])\n",
    "        if 'mse' in df.columns and df['mse'].notna().any():\n",
    "            x_vals = df[x_col].astype(str)\n",
    "            y_vals = df['mse'].fillna(0)\n",
    "            \n",
    "            bars = ax.bar(range(len(x_vals)), y_vals, color='steelblue', alpha=0.7)\n",
    "            ax.set_xticks(range(len(x_vals)))\n",
    "            ax.set_xticklabels(x_vals, rotation=45, ha='right')\n",
    "            ax.set_xlabel(x_col)\n",
    "            ax.set_ylabel('MSE')\n",
    "            ax.set_title(f'{param_key}')\n",
    "            \n",
    "            # Highlight best result\n",
    "            if y_vals.min() > 0:\n",
    "                best_idx = y_vals.idxmin()\n",
    "                bars[best_idx].set_color('green')\n",
    "        else:\n",
    "            ax.text(0.5, 0.5, 'No valid results', ha='center', va='center', transform=ax.transAxes)\n",
    "            ax.set_title(f'{param_key}')\n",
    "    else:\n",
    "        ax.text(0.5, 0.5, 'Not tested', ha='center', va='center', transform=ax.transAxes)\n",
    "        ax.set_title(f'{param_key}')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Create results directory if it doesn't exist\n",
    "\n",
    "results_dir = '/home/ayush/Desktop/tslib/results'plt.show()\n",
    "\n",
    "os.makedirs(results_dir, exist_ok=True)plt.savefig(os.path.join(results_dir, 'timesnet_hyperparameter_results.png'), dpi=150, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7442c334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive results table\n",
    "print(\"=\"*80)\n",
    "print(\"COMPREHENSIVE HYPERPARAMETER TESTING RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "summary_data = []\n",
    "\n",
    "for param_name, results in all_results.items():\n",
    "    if results:\n",
    "        df = pd.DataFrame(results)\n",
    "        if 'mse' in df.columns:\n",
    "            valid_df = df[df['mse'].notna()]\n",
    "            if len(valid_df) > 0:\n",
    "                best_row = valid_df.loc[valid_df['mse'].idxmin()]\n",
    "                worst_row = valid_df.loc[valid_df['mse'].idxmax()]\n",
    "                \n",
    "                # Get the parameter column name\n",
    "                param_col = [c for c in df.columns if c not in ['mse', 'mae', 'success', 'output']][0]\n",
    "                \n",
    "                summary_data.append({\n",
    "                    'Hyperparameter': param_name,\n",
    "                    'Best Value': best_row[param_col],\n",
    "                    'Best MSE': f\"{best_row['mse']:.4f}\" if best_row['mse'] else 'N/A',\n",
    "                    'Best MAE': f\"{best_row['mae']:.4f}\" if best_row.get('mae') else 'N/A',\n",
    "                    'Worst Value': worst_row[param_col],\n",
    "                    'Worst MSE': f\"{worst_row['mse']:.4f}\" if worst_row['mse'] else 'N/A',\n",
    "                    'Tested Values': len(valid_df)\n",
    "                })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "display(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7485c9df",
   "metadata": {},
   "source": [
    "## 8. Final Report\n",
    "\n",
    "### Implementation Used\n",
    "- **Repository**: TSLib (Time-Series-Library) - https://github.com/thuml/Time-Series-Library\n",
    "- **Model File**: `models/TimesNet.py`\n",
    "- **Paper**: TimesNet: Temporal 2D-Variation Modeling for General Time Series Analysis (ICLR 2023)\n",
    "\n",
    "### Key Hyperparameters Identified\n",
    "\n",
    "| Hyperparameter | Type | Description | Recommended Range |\n",
    "|----------------|------|-------------|-------------------|\n",
    "| `top_k` | TimesNet-specific | Number of top frequencies from FFT | 3-7 |\n",
    "| `num_kernels` | TimesNet-specific | Number of 2D kernels in Inception block | 4-8 |\n",
    "| `d_model` | Architecture | Model embedding dimension | 16-128 |\n",
    "| `d_ff` | Architecture | Feed-forward network dimension | 32-256 |\n",
    "| `e_layers` | Architecture | Number of TimesBlock layers | 2-3 |\n",
    "| `learning_rate` | Training | Optimizer learning rate | 1e-4 to 5e-4 |\n",
    "| `dropout` | Regularization | Dropout probability | 0.0-0.2 |\n",
    "| `embed` | Feature Engineering | Time encoding method | timeF (recommended) |\n",
    "\n",
    "### Hyperparameters Not Tested\n",
    "- `batch_size`: Computational constraint (kept at 32)\n",
    "- `seq_len` / `pred_len`: Task-specific, not model hyperparameters\n",
    "- Different 2D vision backbones (paper mentions ResNet, ResNeXt, ConvNeXt as alternatives)\n",
    "\n",
    "### Metadata Feature Testing\n",
    "Linear metadata features (-1 to 1 normalized):\n",
    "- Hour of day\n",
    "- Day of week\n",
    "- Day of month\n",
    "- Month of year\n",
    "- Season\n",
    "- Holiday indicator\n",
    "\n",
    "### Notes\n",
    "1. TimesNet uses FFT to discover periods, so the `top_k` parameter is crucial\n",
    "2. The Inception block with multiple kernel sizes captures multi-scale patterns\n",
    "3. Model is relatively compact compared to other Transformer-based models\n",
    "4. Non-stationary normalization is applied internally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc02b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all results to JSON for future reference\n",
    "import json\n",
    "\n",
    "# Create results directory if it doesn't exist\n",
    "results_dir = '/home/ayush/Desktop/tslib/results'\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# Convert results to serializable format\n",
    "serializable_results = {}\n",
    "for key, results in all_results.items():\n",
    "    serializable_results[key] = []\n",
    "    for r in results:\n",
    "        clean_r = {k: v for k, v in r.items() if k != 'output'}\n",
    "        serializable_results[key].append(clean_r)\n",
    "\n",
    "\n",
    "json_path = os.path.join(results_dir, 'timesnet_hyperparameter_results.json')\n",
    "print(f\"Results saved to {json_path}\")\n",
    "\n",
    "with open(json_path, 'w') as f:\n",
    "    json.dump(serializable_results, f, indent=2, default=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0391353c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export all results to Excel with multiple sheets\n",
    "from datetime import datetime\n",
    "\n",
    "# Create results directory if it doesn't exist\n",
    "results_dir = '/home/ayush/Desktop/tslib/results'\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# Create Excel writer\n",
    "excel_path = os.path.join(results_dir, 'timesnet_hyperparameter_results.xlsx')\n",
    "with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:\n",
    "    \n",
    "    # Sheet 1: Summary of best results for each hyperparameter\n",
    "    if summary_data:\n",
    "        summary_df = pd.DataFrame(summary_data)\n",
    "        summary_df.to_excel(writer, sheet_name='Summary', index=False)\n",
    "    \n",
    "    # Sheet 2: Base model results\n",
    "    base_df = pd.DataFrame([{\n",
    "        'Configuration': 'Base Model (Author Recommended)',\n",
    "        'top_k': 5,\n",
    "        'num_kernels': 6,\n",
    "        'd_model': 16,\n",
    "        'd_ff': 32,\n",
    "        'e_layers': 2,\n",
    "        'seq_len': 96,\n",
    "        'pred_len': 96,\n",
    "        'learning_rate': 0.0001,\n",
    "        'dropout': 0.1,\n",
    "        'embed': 'timeF',\n",
    "        'MSE': base_results.get('mse', 'N/A'),\n",
    "        'MAE': base_results.get('mae', 'N/A')\n",
    "    }])\n",
    "    base_df.to_excel(writer, sheet_name='Base_Model', index=False)\n",
    "    \n",
    "    # Individual sheets for each hyperparameter test\n",
    "    param_sheets = {\n",
    "        'top_k': ['top_k', 'mse', 'mae', 'success'],\n",
    "        'num_kernels': ['num_kernels', 'mse', 'mae', 'success'],\n",
    "        'd_model': ['d_model', 'mse', 'mae', 'success'],\n",
    "        'e_layers': ['e_layers', 'mse', 'mae', 'success'],\n",
    "        'learning_rate': ['learning_rate', 'mse', 'mae', 'success'],\n",
    "        'dropout': ['dropout', 'mse', 'mae', 'success'],\n",
    "        'embed': ['embed', 'mse', 'mae', 'success'],\n",
    "        'metadata': ['config', 'mse', 'mae']\n",
    "    }\n",
    "    \n",
    "    for param_name, columns in param_sheets.items():\n",
    "        if param_name in all_results and all_results[param_name]:\n",
    "            df = pd.DataFrame(all_results[param_name])\n",
    "            # Select only available columns\n",
    "            available_cols = [c for c in columns if c in df.columns]\n",
    "            if available_cols:\n",
    "                df[available_cols].to_excel(writer, sheet_name=f'Test_{param_name}', index=False)\n",
    "    \n",
    "    # Sheet: All results combined\n",
    "    all_rows = []\n",
    "    for param_name, results in all_results.items():\n",
    "        if results:\n",
    "            for r in results:\n",
    "                row = {'Hyperparameter': param_name}\n",
    "                row.update({k: v for k, v in r.items() if k != 'output'})\n",
    "                all_rows.append(row)\n",
    "    \n",
    "    if all_rows:\n",
    "        all_combined_df = pd.DataFrame(all_rows)\n",
    "        all_combined_df.to_excel(writer, sheet_name='All_Results', index=False)\n",
    "    \n",
    "    # Sheet: Experiment metadata\n",
    "    metadata_df = pd.DataFrame([{\n",
    "        'Experiment_Date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'Model': 'TimesNet',\n",
    "        'Implementation': 'TSLib (github.com/thuml/Time-Series-Library)',\n",
    "        'Dataset': 'ETTh1',\n",
    "        'Task': 'Long-term Forecasting',\n",
    "        'Base_Seq_Len': 96,\n",
    "        'Base_Pred_Len': 96,\n",
    "        'Train_Epochs': base_config.get('train_epochs', 5),\n",
    "        'Notes': 'Hyperparameter sensitivity analysis'\n",
    "    }])\n",
    "    metadata_df.to_excel(writer, sheet_name='Experiment_Info', index=False)\n",
    "\n",
    "print(f\"âœ“ Results exported to Excel: {excel_path}\")\n",
    "print(f\"  Sheets created:\")\n",
    "print(f\"    - Summary: Best results for each hyperparameter\")\n",
    "\n",
    "print(f\"    - Base_Model: Author's recommended configuration\")print(f\"    - Experiment_Info: Experiment metadata\")\n",
    "\n",
    "print(f\"    - Test_*: Individual hyperparameter test results\")print(f\"    - All_Results: Combined results table\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
